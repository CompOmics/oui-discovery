{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d5baec-885f-4e4a-bc21-9f14a8330196",
   "metadata": {},
   "source": [
    "Project 1 = https://www.ebi.ac.uk/pride/archive/projects/PXD002057\n",
    "\n",
    "Project 2 = https://www.ebi.ac.uk/pride/archive/projects/PXD05388\n",
    "\n",
    "Project 3 = https://www.ebi.ac.uk/pride/archive/projects/PXD003594\n",
    "\n",
    "\"Canonical\" search database contains only UniProt SwissProt canonical protein sequences (Uniprot version 2023_01).\n",
    "\n",
    "\"trEMBL\" search database includes protein isoforms and trEMBL sequences (Uniprot version 2023_01)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6402f-0bf5-4cd6-adda-0f77f49d4514",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed024f-862f-4f0c-a6ae-5ee9ac07593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import pyteomics.auxiliary as aux\n",
    "import seaborn as sns\n",
    "import os, re, subprocess\n",
    "from utility_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00008a-ac3e-4543-8d1c-96d5ca75ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_folder = \"C:/Users/pc/OneDrive - UGent/run-ionbot\"\n",
    "# working_folder = \"D:/run-ionbot\"\n",
    "PXDs = [\n",
    "    # 'PXD002057-closed',\n",
    "    # 'PXD005833-closed',\n",
    "    # 'PXD014258-closed',\n",
    "    'PXD002057.v0.11.4',\n",
    "    # 'PXD005833.v0.11.4',\n",
    "    # 'PXD014258.v0.11.4',\n",
    "]\n",
    "SEARCHES = [\n",
    "    # 'canon',\n",
    "    # 'trembl',\n",
    "    'openprot',\n",
    "]\n",
    "DATASETS = pd.MultiIndex.from_product([PXDs,SEARCHES])\n",
    "DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608f1d7-fd62-4dc0-a59e-7c8e84a71c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = {dataset_name:{search:[] for search in SEARCHES} for dataset_name in PXDs}\n",
    "for dataset_name in PXDs:\n",
    "    for search in SEARCHES:   \n",
    "        for fld in os.scandir(os.path.join(working_folder, dataset_name, f\"{dataset_name}-{search}\")):\n",
    "            if not fld.name.startswith('.') and os.path.isdir(fld.path): \n",
    "                folders[dataset_name][search].append(fld)\n",
    "# folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d378e-284d-4ea9-a2a7-bf171ef84e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = []\n",
    "for dataset_name in PXDs:\n",
    "    for search in SEARCHES:  \n",
    "        j = len(folders[dataset_name][search])\n",
    "        for i,sample_fld in enumerate(folders[dataset_name][search]):            \n",
    "            # Read and preprocess the dataset\n",
    "            data = pd.read_csv(os.path.join(sample_fld.path,'ionbot.first.csv'))\n",
    "            print(f'({1+i}/{j})',sample_fld, data.shape)\n",
    "            # num_psms = len(data)\n",
    "            data.drop(columns=['q-value', 'PEP'], inplace=True)\n",
    "            data.modifications = data.modifications.fillna('Unmodified')\n",
    "            data = aux.target_decoy.qvalues(data,\n",
    "                                            key='psm_score',\n",
    "                                            reverse=True,\n",
    "                                            is_decoy=(data.database == 'D'),\n",
    "                                            q_label='q-value',\n",
    "                                            formula=1,\n",
    "                                            full_output=True)\n",
    "            data.sort_values('database', ascending=False, inplace=True)\n",
    "            data.unexpected_modification = data.unexpected_modification.fillna('')\n",
    "            \n",
    "            # Process proteins column and compute associated features\n",
    "            data['proteins'] = data.proteins.apply(process_proteins)\n",
    "            data['leadprot'] = data.proteins.apply(lambda x: x[0])\n",
    "            data['protein_classes'] = data.proteins.apply(\n",
    "                lambda lst: np.unique([classify_leadprot(p) for p in lst])\n",
    "            )\n",
    "            \n",
    "            data['isCanonical'] = data.protein_classes.apply(is_peptide_canonical)\n",
    "            data['isModified'] = data.apply(classifiy_mods, axis=1)\n",
    "            \n",
    "            # Apply custom subgroup filter and compute Group-walk specific columns\n",
    "            data2 = custom_subgroup_filter(data)\n",
    "            data2['isTarget'] = data2.database.eq('T').astype(int)\n",
    "            data2['FDRGroup'] = data2.isCanonical + '_' + data2.isModified\n",
    "            \n",
    "            # Convert list columns to semicolon-separated strings for CSV export\n",
    "            data2['proteins'] = data2.proteins.apply(lambda lst: ';'.join(lst))\n",
    "            data2['protein_classes'] = data2.protein_classes.apply(lambda lst: ';'.join(lst))\n",
    "            \n",
    "            # Save the processed data & prepare for groupwalk\n",
    "            out_fld = sample_fld.path\n",
    "            IN  = os.path.join(out_fld, \"group-walk-input.csv\")\n",
    "            OUT = os.path.join(out_fld, \"group-walk-output.csv\")\n",
    "            data2.to_csv(IN, index=False)\n",
    "            print(out_fld, data2.shape)\n",
    "            # print(num_psms==len(data2))\n",
    "    \n",
    "            # Run Groupwalk\n",
    "            print(\"GroupWalk run start...\")\n",
    "            _ = subprocess.run(['Rscript.exe', 'Run_group_walk.R', os.getcwd(), IN, OUT])\n",
    "            print(\"GroupWalk run OK =\",_.returncode==0)\n",
    "            os.remove(IN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac39c87-3aa0-4c3a-b4de-072361f28544",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in PXDs:\n",
    "    for search in SEARCHES: \n",
    "        tmp = []\n",
    "        for fld in folders[dataset_name][search]:\n",
    "            tmp.append(pd.read_csv(os.path.join(fld.path,\"group-walk-output.csv\"), low_memory=False))\n",
    "        tmp = pd.concat(tmp, ignore_index=True)\n",
    "        tmp.to_csv(os.path.join(working_folder, dataset_name, f'{dataset_name}-{search}',\n",
    "                                f\"combined-results-w-qvalues.csv.gz\"),\n",
    "                   index=False, compression='gzip')\n",
    "        TD = tmp.database.value_counts()\n",
    "        print(dataset_name, search, f\"FDR={TD['D']/TD['T']:.2%}\")\n",
    "        del tmp\n",
    "print('\\nDone!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a23f4d-e49a-4290-a7db-b3f541da5f06",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d9ed7-6706-48dd-a049-2c1f5e7a32d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders = {search:[] for search in SEARCHES}\n",
    "# for search in SEARCHES:   \n",
    "#     for dataset_name in PXDs:\n",
    "#         for fld in os.scandir(os.path.join(working_folder, dataset_name, f\"{dataset_name}-{search}\")):\n",
    "#             if not fld.name.startswith('.') and os.path.isdir(fld.path): \n",
    "#                 folders[search].append([dataset_name,fld])\n",
    "# folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bdaf4b-9251-444a-9431-9d467c9d26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering='custom'\n",
    "# for dataset_name in PXDs:\n",
    "#     for search in SEARCHES: \n",
    "#         tmp = []\n",
    "#         for fld in folders[dataset_name][search]:\n",
    "#             tmp.append(pd.read_csv(os.path.join(fld.path,\"group-walk-output.csv\")))\n",
    "#             # tmp.append(import_pep_IDs(os.path.join(fld.path,\"group-walk-output.csv\"), filtering=filtering))\n",
    "#         tmp = pd.concat(tmp, ignore_index=True)\n",
    "#         tmp.to_csv(os.path.join(working_folder, dataset_name, f'{dataset_name}-{search}',\n",
    "#                                 f\"combined-results-w-qvalues.csv.gz\"),\n",
    "#                    index=False, compression='gzip')\n",
    "#         TD = tmp.database.value_counts()\n",
    "#         # print(TD)\n",
    "#         print(dataset_name, search, f\"FDR={TD['D']/TD['T']:.2%}\")\n",
    "#         del tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
